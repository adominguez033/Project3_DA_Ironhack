# Project3_DA_Ironhack
![img](https://www.google.com/search?q=elon+musk+tesla+price+tweet&tbm=isch&ved=2ahUKEwiztpXaxM_4AhVK8BoKHZ8xBXwQ2-cCegQIABAA&oq=tesla+price+tw&gs_lcp=CgNpbWcQARgAMgYIABAeEAU6BAgjECc6BwgAELEDEEM6BAgAEEM6CAgAEIAEELEDOgoIABCxAxCDARBDOgUIABCABDoECAAQAzoECAAQHjoECAAQEzoICAAQHhAFEBM6CAgAEB4QCBATULIGWOYbYNgvaAFwAHgDgAGaB4gB4BiSAQgxMS41LTEuMpgBAKABAaoBC2d3cy13aXotaW1nwAEB&sclient=img&ei=DqK6YrP3DMrga5_jlOAH&bih=653&biw=1429#imgrc=IBgPj4h5SvbsGM)

## Introduction

This repo contains the work done in the third project of the Data Analytics Bootcamp (June 2022). During the forth week, web data extraction from the web has been taught. This means, so far entire ETL is known: from extracting data, to clean it and transform it and upload into a database.
This project entails:

1. **Extracting data from three different sources using two different extraction methods.** 

1. **Cleaning the datasets and transform them**

1. **Create the database, upload the cleaned data**

## Data extraction.

Data extraction has been done thorugh the following sources and using the following methods:

1. **CSV from NASDAQ (Tesla Stock price)** --> https://www.nasdaq.com/es/market-activity/stocks/tsla/historical

1. **CSV from Kaggle (All Elon Musk Tweets)**  --> https://www.kaggle.com/datasets/neelgajare/all-elon-musk-tweets-2022-updated

1. **Web Scraping using Beautiful Soup (Tesla important news)** --> https://ir.tesla.com/press?page=



## Data cleaning.

Data cleaning has been done for the different datasets. Process: 

1. **Data import & raw data information.** 

1. **Null values data cleaning** 

1. **Determination of data type per column**

1. **Data export to csv** 


## Database, tables and relationships creation through Workbench.

Once data has been cleaned, the next step has been to create the database, the different tables (as well as the different columns in each table and its data type) and finally, the relationships between the different tables.


## Data import.

Previous to launch queries, the cleaned data needs to be imported ino the created databse. This has been the hardest part of the project, since several error appeared because of errors incurred in previous steps.


## Queries.

In order to taste the databse, final step has been to launch queries:
### Query nº1: 

### Query nº2 : 

### Query nº3 : 

### Query nº4 : 

### Query nº5 : 

### Query nº6 : 

End of Project 3!!
